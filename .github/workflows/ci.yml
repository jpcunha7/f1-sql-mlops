name: CI

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]

jobs:
  lint-and-test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.11", "3.12"]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Run linter (ruff)
        run: |
          ruff check src/ tests/

      - name: Run tests (pytest)
        run: |
          pytest tests/ -v --tb=short

  data-pipeline:
    runs-on: ubuntu-latest
    needs: lint-and-test

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .

      - name: Generate toy data
        run: |
          python -m f1sqlmlops.ingestion.generate_toy_data

      - name: Validate schemas
        run: |
          python -m f1sqlmlops.quality.schema_checks --parquet-dir data/toy_parquet

      - name: Register Parquet views in DuckDB
        run: |
          PARQUET_DIR=data/toy_parquet python -m f1sqlmlops.warehouse.duckdb_utils
        env:
          PARQUET_DIR: data/toy_parquet

      - name: Run dbt models
        run: |
          cp dbt/profiles.yml.example dbt/profiles.yml
          cd dbt && dbt deps && dbt build --profiles-dir .

      - name: Export features
        run: |
          python -m f1sqlmlops.features.export_features --output-dir data/features

      - name: Upload feature data
        uses: actions/upload-artifact@v4
        with:
          name: features-${{ github.sha }}
          path: data/features/
          retention-days: 7

  smoke-test-training:
    runs-on: ubuntu-latest
    needs: data-pipeline

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .

      - name: Download features
        uses: actions/download-artifact@v4
        with:
          name: features-${{ github.sha }}
          path: data/features/

      - name: Generate toy data (needed for DuckDB)
        run: |
          python -m f1sqlmlops.ingestion.generate_toy_data
          PARQUET_DIR=data/toy_parquet python -m f1sqlmlops.warehouse.duckdb_utils
        env:
          PARQUET_DIR: data/toy_parquet

      - name: Smoke test - Train Top-10 model
        run: |
          python -m f1sqlmlops.training.train_top10 --n-estimators 10 --max-depth 3

      - name: Smoke test - Train DNF model
        run: |
          python -m f1sqlmlops.training.train_dnf --n-estimators 10 --max-depth 3

      - name: Verify models were created
        run: |
          ls -lh models/
          test -f models/top10_classifier.pkl
          test -f models/dnf_classifier.pkl

      - name: Smoke test - Evaluation
        run: |
          python -m f1sqlmlops.training.evaluate

      - name: Upload trained models
        uses: actions/upload-artifact@v4
        with:
          name: models-${{ github.sha }}
          path: models/
          retention-days: 7

  inference-test:
    runs-on: ubuntu-latest
    needs: smoke-test-training

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .

      - name: Download models
        uses: actions/download-artifact@v4
        with:
          name: models-${{ github.sha }}
          path: models/

      - name: Generate toy data
        run: |
          python -m f1sqlmlops.ingestion.generate_toy_data
          PARQUET_DIR=data/toy_parquet python -m f1sqlmlops.warehouse.duckdb_utils
        env:
          PARQUET_DIR: data/toy_parquet

      - name: Run dbt models
        run: |
          cp dbt/profiles.yml.example dbt/profiles.yml
          cd dbt && dbt deps && dbt build --profiles-dir .

      - name: Test inference - specific race
        run: |
          python -m f1sqlmlops.inference.predict --from-db --year 2020 --race-id 1 --summary

      - name: Test inference - full year
        run: |
          python -m f1sqlmlops.inference.predict --from-db --year 2020 --summary

  docker-build:
    runs-on: ubuntu-latest
    needs: lint-and-test

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile
          push: false
          tags: f1-sql-mlops:ci-${{ github.sha }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Validate docker-compose
        run: |
          docker compose version
          docker compose config
